{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPdOUvCWaORI3mGqAj/Qfol",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajkohl/AdversarialAttacksResnet/blob/main/HyperBolicGCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYiEJmccXcZz",
        "outputId": "bdf498ee-b73e-45ee-ab49-de9e8e74bfe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting geoopt\n",
            "  Downloading geoopt-0.5.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from geoopt) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from geoopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from geoopt) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->geoopt) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->geoopt) (3.0.2)\n",
            "Downloading geoopt-0.5.0-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: geoopt\n",
            "Successfully installed geoopt-0.5.0\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install geoopt\n",
        "!pip install networkx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import geoopt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# If you choose to use torch_geometric, uncomment the following:\n",
        "# !pip install torch-scatter torch-sparse torch-geometric\n",
        "# from torch_geometric.data import Data\n"
      ],
      "metadata": {
        "id": "NSf0fRKaYY4m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming train.txt, valid.txt, and test.txt are uploaded to your Colab environment.\n",
        "\n",
        "def load_fb15k_triples(file_path):\n",
        "    triples = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            head, rel, tail = line.strip().split('\\t')\n",
        "            triples.append((head, rel, tail))\n",
        "    return triples\n",
        "\n",
        "train_triples = load_fb15k_triples('train.txt')\n",
        "valid_triples = load_fb15k_triples('valid.txt')\n",
        "test_triples = load_fb15k_triples('test.txt')\n",
        "\n",
        "# Extract unique entities and relations\n",
        "entities = set()\n",
        "relations = set()\n",
        "\n",
        "for (h, r, t) in train_triples:\n",
        "    entities.add(h)\n",
        "    entities.add(t)\n",
        "    relations.add(r)\n",
        "\n",
        "entities = list(entities)\n",
        "relations = list(relations)\n",
        "\n",
        "entity2id = {e: i for i, e in enumerate(entities)}\n",
        "rel2id = {r: i for i, r in enumerate(relations)}\n",
        "\n",
        "num_entities = len(entity2id)\n",
        "num_relations = len(rel2id)\n",
        "\n",
        "print(\"Number of entities:\", num_entities)\n",
        "print(\"Number of relations:\", num_relations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjubqxcrYbTb",
        "outputId": "d273832c-f12f-49b3-d25c-c5a213cdedff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entities: 14505\n",
            "Number of relations: 237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.MultiDiGraph()\n",
        "for (h, r, t) in train_triples:\n",
        "    G.add_node(entity2id[h])\n",
        "    G.add_node(entity2id[t])\n",
        "    G.add_edge(entity2id[h], entity2id[t], key=rel2id[r])\n"
      ],
      "metadata": {
        "id": "fbw7KUnPYd7D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def negative_sampling(triples, num_entities, neg_size=1):\n",
        "    # Simple uniform random negative sampler\n",
        "    neg_triples = []\n",
        "    for (h, r, t) in triples:\n",
        "        h_id = entity2id[h]\n",
        "        r_id = rel2id[r]\n",
        "        t_id = entity2id[t]\n",
        "        for _ in range(neg_size):\n",
        "            # Replace tail with random entity\n",
        "            neg_t = np.random.randint(0, num_entities)\n",
        "            neg_triples.append((h_id, r_id, neg_t))\n",
        "    return neg_triples\n",
        "\n",
        "neg_train_triples = negative_sampling(train_triples, num_entities, neg_size=1)\n"
      ],
      "metadata": {
        "id": "xVAjkuG-YpF8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FB15kDataset(Dataset):\n",
        "    def __init__(self, pos_triples, neg_triples):\n",
        "        self.pos = pos_triples\n",
        "        self.neg = neg_triples\n",
        "        self.len = len(self.pos)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ph, pr, pt = self.pos[idx]\n",
        "        nh, nr, nt = self.neg[idx]\n",
        "        return (ph, pr, pt, nh, nr, nt)\n",
        "\n",
        "# Convert positives to IDs\n",
        "train_pos_ids = [(entity2id[h], rel2id[r], entity2id[t]) for (h,r,t) in train_triples]\n",
        "train_neg_ids = neg_train_triples\n",
        "\n",
        "train_dataset = FB15kDataset(train_pos_ids, train_neg_ids)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n"
      ],
      "metadata": {
        "id": "6ZDw9ylNYrvS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Poincaré ball\n",
        "manifold = geoopt.manifolds.PoincareBall()\n",
        "curvature = torch.nn.Parameter(torch.tensor([1.0]), requires_grad=True)  # Curvature as a learnable param\n"
      ],
      "metadata": {
        "id": "k37Gv_C3YtgK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entity_emb = geoopt.ManifoldParameter(torch.randn(num_entities, 64), manifold=manifold)\n",
        "rel_emb = geoopt.ManifoldParameter(torch.randn(num_relations, 64), manifold=manifold)\n"
      ],
      "metadata": {
        "id": "SU5d7U8gYvXk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HypGraphConvolution(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, manifold):\n",
        "        super().__init__()\n",
        "        self.manifold = manifold\n",
        "        self.weight = geoopt.ManifoldParameter(torch.randn(in_dim, out_dim), manifold=manifold)\n",
        "        # For simplicity, treat weight as manifold param. A real HGCN would do more complex ops.\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # A placeholder: aggregate neighbors’ embeddings and transform\n",
        "        # adj: adjacency matrix or edge index. Here, we simply apply a linear transform.\n",
        "        # In a real scenario, implement hyperbolic message passing using Möbius addition, etc.\n",
        "        return self.manifold.projx(self.manifold.expmap0(x @ self.weight, k=curvature))\n"
      ],
      "metadata": {
        "id": "M0WCYEKxYxbn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HGCNModel(nn.Module):\n",
        "    def __init__(self, entity_emb, rel_emb, manifold, curvature, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.manifold = manifold\n",
        "        self.curvature = curvature\n",
        "        self.entity_emb = entity_emb\n",
        "        self.rel_emb = rel_emb\n",
        "        self.gc1 = HypGraphConvolution(64, 64, manifold)\n",
        "        self.gc2 = HypGraphConvolution(64, 64, manifold)\n",
        "\n",
        "    def forward(self, h, r, t):\n",
        "        # For scoring triples:\n",
        "        # We interpret relation embedding as a \"translation\" in hyperbolic space.\n",
        "        # Score = -hyperbolic_distance(h ⊗ r, t)\n",
        "\n",
        "        # Hypothetical combination:\n",
        "        head = self.entity_emb[h]\n",
        "        rel = self.rel_emb[r]\n",
        "        tail = self.entity_emb[t]\n",
        "\n",
        "        # Just pass them through GCN layers for demonstration (no adjacency here for brevity)\n",
        "        head = self.gc1(head, None)\n",
        "        head = self.gc2(head, None)\n",
        "\n",
        "        tail = self.gc1(tail, None)\n",
        "        tail = self.gc2(tail, None)\n",
        "\n",
        "        rel = self.gc1(rel, None)\n",
        "        rel = self.gc2(rel, None)\n",
        "\n",
        "        # Combine head and relation (Möbius addition in Poincaré)\n",
        "        hr = self.manifold.mobius_add(head, rel, k=self.curvature)\n",
        "\n",
        "        # Distance in Poincaré ball\n",
        "        dist = self.manifold.dist(hr, tail, k=self.curvature)\n",
        "        # Score: lower distance = higher score\n",
        "        return -dist\n"
      ],
      "metadata": {
        "id": "rH7HmTpZYy1U"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RiemannianLBFGS(torch.optim.Optimizer):\n",
        "    def __init__(self, params, lr=1.0, history_size=10):\n",
        "        defaults = dict(lr=lr, history_size=history_size)\n",
        "        super().__init__(params, defaults)\n",
        "        self.state = {}\n",
        "        # For simplicity, we won't fully implement L-BFGS memory here.\n",
        "        # Real implementation would store curvature pairs (s, y).\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        # closure: A function re-evaluating the model and returning loss.\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        # Just a placeholder: a real implementation would do:\n",
        "        # 1. Compute Riemannian gradient from Euclidean gradient\n",
        "        # 2. Apply L-BFGS two-loop recursion to get search direction\n",
        "        # 3. Update parameters via manifold exponential map\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                # Project gradient to tangent space and apply Riemannian step\n",
        "                grad = p.grad\n",
        "                # geoopt manifold optimization step\n",
        "                # In a proper setup, we'd use the stored inverse Hessian approximation.\n",
        "                # Here we do a naive gradient step as a placeholder:\n",
        "                update = -lr * grad\n",
        "                p.data = p.manifold.expmap(p, update, k=curvature)\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "_YE1jBI3Y0t1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HGCNModel(entity_emb, rel_emb, manifold, curvature=1)\n",
        "margin = 1.0\n",
        "\n",
        "# Use our conceptual L-BFGS\n",
        "optimizer = RiemannianLBFGS(model.parameters(), lr=0.1)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        ph, pr, pt, nh, nr, nt = batch\n",
        "        ph, pr, pt = ph.long(), pr.long(), pt.long()\n",
        "        nh, nr, nt = nh.long(), nr.long(), nt.long()\n",
        "\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            pos_score = model(ph, pr, pt)\n",
        "            neg_score = model(nh, nr, nt)\n",
        "            # margin-based ranking loss\n",
        "            loss = F.relu(margin + neg_score - pos_score).mean()\n",
        "            loss.backward()\n",
        "            return loss\n",
        "\n",
        "        loss = optimizer.step(closure)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch} - Loss: {total_loss/len(train_loader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "mRWDBPYaY2LB",
        "outputId": "69720472-57bd-4de9-b645-3e2ab0e35940"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "HypGraphConvolution.__init__() missing 1 required positional argument: 'curvature'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4a0e370ec22e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHGCNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanifold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmargin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Use our conceptual L-BFGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRiemannianLBFGS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-9bcfe5246d68>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, entity_emb, rel_emb, manifold, curvature, hidden_dim)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrel_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHypGraphConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanifold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHypGraphConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanifold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: HypGraphConvolution.__init__() missing 1 required positional argument: 'curvature'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import geoopt\n",
        "\n",
        "# Assuming `manifold` is a PoincaréBall instance and `curvature` a learnable parameter\n",
        "# from previous code sections.\n",
        "\n",
        "########################\n",
        "# Hyperbolic Operations\n",
        "########################\n",
        "\n",
        "def mobius_add(x, y, k, dim=-1):\n",
        "    \"\"\"Möbius addition on Poincaré ball.\"\"\"\n",
        "    # From Ganea et al. (2018): Hyperbolic Neural Networks.\n",
        "    x2 = torch.sum(x * x, dim=dim, keepdim=True)\n",
        "    y2 = torch.sum(y * y, dim=dim, keepdim=True)\n",
        "    xy = torch.sum(x * y, dim=dim, keepdim=True)\n",
        "    c = k\n",
        "    num = (1 + 2*c*xy + c*y2) * x + (1 - c*x2)*y\n",
        "    denom = 1 + 2*c*xy + c**2 * x2 * y2\n",
        "    return num / (denom + 1e-15)\n",
        "\n",
        "def mobius_scalar_mul(r, x, k, dim=-1):\n",
        "    \"\"\"Möbius scalar multiplication.\"\"\"\n",
        "    normx = torch.norm(x, p=2, dim=dim, keepdim=True)\n",
        "    # scale radius by this factor:\n",
        "    return mobius_pointwise_mul(torch.tanh(r * atanh(torch.sqrt(k) * normx) / (torch.sqrt(k) * (normx + 1e-15))),\n",
        "                                x, normx, dim)\n",
        "\n",
        "def mobius_pointwise_mul(factor, x, normx, dim=-1):\n",
        "    return factor * (x / (normx + 1e-15))\n",
        "\n",
        "def atanh(x, eps=1e-15):\n",
        "    return 0.5 * torch.log((1 + x)/(1 - x + eps))\n",
        "\n",
        "def mobius_matmul(x, w, k):\n",
        "    \"\"\"Möbius matrix multiplication: a linear transform in the tangent space followed by exp back.\"\"\"\n",
        "    # We map x to tangent space at 0 using log map, do linear transform, then exp map back.\n",
        "    # For simplicity, assume x is close to zero or just do standard Euclidean matmul followed by projection.\n",
        "    # More rigor would require a full tangent -> Euclidean -> tangent conversion.\n",
        "    x_tan = expmap0(x, k)\n",
        "    x_tan_w = x_tan @ w  # standard linear transform in tangent space\n",
        "    return projx(exmap0_inv(x_tan_w, k), k)  # map back to manifold\n",
        "\n",
        "def expmap0(u, k):\n",
        "    \"\"\"Exponential map at 0.\"\"\"\n",
        "    normu = torch.norm(u, p=2, dim=-1, keepdim=True)\n",
        "    return torch.tanh(torch.sqrt(k)*normu)/(torch.sqrt(k)*normu) * u\n",
        "\n",
        "def logmap0(x, k):\n",
        "    \"\"\"Log map at 0.\"\"\"\n",
        "    normx = torch.norm(x, p=2, dim=-1, keepdim=True)\n",
        "    return (1.0/torch.sqrt(k)*atanh(torch.sqrt(k)*normx)/(normx+1e-15))*x\n",
        "\n",
        "def exmap0_inv(x, k):\n",
        "    # Actually logmap0 is the inverse of expmap0. Use logmap0 instead for clarity.\n",
        "    return logmap0(x, k)\n",
        "\n",
        "def projx(x, k):\n",
        "    \"\"\"Project onto Poincaré ball.\"\"\"\n",
        "    normx = torch.norm(x, p=2, dim=-1, keepdim=True)\n",
        "    maxnorm = (1 - 1e-5) / torch.sqrt(k)\n",
        "    cond = normx > maxnorm\n",
        "    # If normx too big, rescale\n",
        "    projected = x/ normx * maxnorm\n",
        "    x = torch.where(cond, projected, x)\n",
        "    return x\n",
        "\n",
        "########################\n",
        "# Hyperbolic Linear Layer\n",
        "########################\n",
        "\n",
        "class HypLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, manifold, k):\n",
        "        super().__init__()\n",
        "        self.manifold = manifold\n",
        "        self.k = k\n",
        "        self.weight = nn.Parameter(torch.randn(in_features, out_features)*0.01)\n",
        "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Map x to tangent space at 0\n",
        "        x_tan = logmap0(x, self.k)\n",
        "        # Linear transform in tangent space\n",
        "        out = x_tan @ self.weight + self.bias\n",
        "        # Map back to the manifold\n",
        "        out_hyp = expmap0(out, self.k)\n",
        "        return projx(out_hyp, self.k)\n",
        "\n",
        "########################\n",
        "# Hyperbolic Graph Convolution Layer\n",
        "########################\n",
        "\n",
        "class HypGraphConvolution(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, manifold, curvature):\n",
        "        super().__init__()\n",
        "        self.manifold = manifold\n",
        "        self.curvature = curvature\n",
        "        self.hyp_linear = HypLinear(in_dim, out_dim, manifold, curvature)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # adj is the adjacency matrix or a normalized adjacency\n",
        "        # For simplicity, let's assume adj is a sparse adjacency matrix or dense tensor\n",
        "        # We'll do a basic mean aggregator:\n",
        "\n",
        "        # Aggregate neighbors in tangent space\n",
        "        x_tan = logmap0(x, self.curvature)\n",
        "        # Mean aggregator in tangent space (adj assumed to be NxN)\n",
        "        # shape: x_tan: [N, D], adj: [N, N]\n",
        "        agg = adj @ x_tan\n",
        "        # Normalize by degree if needed\n",
        "        deg = torch.sum(adj, dim=-1, keepdim=True)\n",
        "        agg = agg / (deg + 1e-15)\n",
        "\n",
        "        # Map aggregated features back to manifold\n",
        "        agg_hyp = expmap0(agg, self.curvature)\n",
        "        agg_hyp = projx(agg_hyp, self.curvature)\n",
        "\n",
        "        # Apply a hyperbolic linear transform\n",
        "        out = self.hyp_linear(agg_hyp)\n",
        "        return projx(out, self.curvature)\n",
        "\n",
        "########################\n",
        "# Riemannian L-BFGS Optimizer (Initial Implementation)\n",
        "########################\n",
        "\n",
        "class RiemannianLBFGS(torch.optim.Optimizer):\n",
        "    def __init__(self, params, lr=1.0, history_size=10, line_search=False):\n",
        "        defaults = dict(lr=lr, history_size=history_size, line_search=line_search)\n",
        "        super().__init__(params, defaults)\n",
        "        self._params = self.param_groups[0]['params']\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        # Collect gradients and prepare for Riemannian step\n",
        "        grad = []\n",
        "        for p in self._params:\n",
        "            if p.grad is not None:\n",
        "                # Project gradient to tangent space if needed\n",
        "                # geoopt handles gradient projection automatically for ManifoldParameter,\n",
        "                # but if needed, we can ensure it:\n",
        "                # p.grad = p.manifold.egrad2rgrad(p, p.grad)\n",
        "                grad.append(p.grad.view(-1))\n",
        "\n",
        "        if len(grad) == 0:\n",
        "            return loss\n",
        "\n",
        "        # Flatten gradients\n",
        "        grad = torch.cat(grad)\n",
        "\n",
        "        group = self.param_groups[0]\n",
        "        state = self.state\n",
        "        lr = group['lr']\n",
        "        history_size = group['history_size']\n",
        "\n",
        "        # Initialize state if needed\n",
        "        if 'old_dirs' not in state:\n",
        "            state['old_dirs'] = []\n",
        "            state['old_stps'] = []\n",
        "            state['H_diag'] = 1.0\n",
        "\n",
        "        old_dirs = state['old_dirs']\n",
        "        old_stps = state['old_stps']\n",
        "        H_diag = state['H_diag']\n",
        "\n",
        "        # Two-loop recursion to compute search direction\n",
        "        q = grad\n",
        "        alpha = []\n",
        "\n",
        "        for i in reversed(range(len(old_dirs))):\n",
        "            s = old_dirs[i]\n",
        "            y = old_stps[i]\n",
        "            alpha_i = (s @ q)/(y @ s)\n",
        "            alpha.append(alpha_i)\n",
        "            q = q - alpha_i * y\n",
        "\n",
        "        # initial H0 * q\n",
        "        q = H_diag * q\n",
        "\n",
        "        # now iterate forward\n",
        "        for i in range(len(old_dirs)):\n",
        "            s = old_dirs[i]\n",
        "            y = old_stps[i]\n",
        "            beta = (y @ q)/(y @ s)\n",
        "            q = q + s*(alpha[-(i+1)] - beta)\n",
        "\n",
        "        # q is now the search direction in the Euclidean sense.\n",
        "        # We need to perform a Riemannian update:\n",
        "\n",
        "        # Update parameters along q\n",
        "        idx = 0\n",
        "        for p in self._params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            size = p.numel()\n",
        "            dq = q[idx:idx+size].view_as(p)\n",
        "            idx += size\n",
        "\n",
        "            # Riemannian update:\n",
        "            # Move p along q using exponential map\n",
        "            # We assume p is on a geoopt manifold. Using manifold.expmap:\n",
        "            p.data = p.manifold.expmap(p.data, -lr * dq, k=curvature)\n",
        "\n",
        "        # Update memory for L-BFGS\n",
        "        # On the next iteration, we will have a new gradient. Let’s store s and y:\n",
        "        # s = delta parameters, y = delta gradient\n",
        "        # We'll need to do this on next step call. Typically, this involves storing\n",
        "        # param changes and grad changes from previous iteration. For simplicity here,\n",
        "        # assume we can do:\n",
        "\n",
        "        # Actually, to store s, y properly, we need the old parameters and old gradients.\n",
        "        # Let's store them now:\n",
        "        if 'prev_params' in state:\n",
        "            prev_params = state['prev_params']\n",
        "            prev_grads = state['prev_grads']\n",
        "            new_params = [p.data.clone() for p in self._params]\n",
        "            new_grads = [p.grad.data.clone() if p.grad is not None else torch.zeros_like(p.data) for p in self._params]\n",
        "\n",
        "            # compute s and y\n",
        "            s_flat = []\n",
        "            y_flat = []\n",
        "            for old_p, new_p, old_g, new_g in zip(prev_params, new_params, prev_grads, new_grads):\n",
        "                s_flat.append((new_p - old_p).view(-1))\n",
        "                y_flat.append((new_g - old_g).view(-1))\n",
        "            s_flat = torch.cat(s_flat)\n",
        "            y_flat = torch.cat(y_flat)\n",
        "\n",
        "            # Update memory\n",
        "            if len(old_dirs) == history_size:\n",
        "                old_dirs.pop(0)\n",
        "                old_stps.pop(0)\n",
        "            old_dirs.append(s_flat)\n",
        "            old_stps.append(y_flat)\n",
        "\n",
        "            # Update H_diag\n",
        "            # Typically H0 is chosen as (s@y)/(y@y)\n",
        "            H_diag = (s_flat @ y_flat)/(y_flat @ y_flat + 1e-15)\n",
        "            state['H_diag'] = H_diag\n",
        "\n",
        "            # Save new params and grads\n",
        "            state['prev_params'] = new_params\n",
        "            state['prev_grads'] = new_grads\n",
        "        else:\n",
        "            # First iteration, just record\n",
        "            state['prev_params'] = [p.data.clone() for p in self._params]\n",
        "            state['prev_grads'] = [p.grad.data.clone() if p.grad is not None else torch.zeros_like(p.data) for p in self._params]\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "jpdIxy_7Y4ZJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geoopt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import geoopt\n",
        "\n",
        "########################\n",
        "# Hyperbolic Utility Functions\n",
        "########################\n",
        "\n",
        "def atanh(x, eps=1e-15):\n",
        "    return 0.5 * torch.log((1 + x)/(1 - x + eps))\n",
        "\n",
        "def expmap0(u, k):\n",
        "    \"\"\"Exponential map at 0 on the Poincaré ball.\"\"\"\n",
        "    normu = torch.clamp_min(torch.norm(u, p=2, dim=-1, keepdim=True), 1e-15)\n",
        "    sqrtk = torch.sqrt(k)\n",
        "    return torch.tanh(sqrtk * normu) * u / (sqrtk * normu)\n",
        "\n",
        "def logmap0(x, k):\n",
        "    \"\"\"Log map at 0 on the Poincaré ball.\"\"\"\n",
        "    normx = torch.clamp_min(torch.norm(x, p=2, dim=-1, keepdim=True), 1e-15)\n",
        "    sqrtk = torch.sqrt(k)\n",
        "    return (1./(sqrtk)) * atanh(sqrtk*normx) * x / normx\n",
        "\n",
        "def projx(x, k):\n",
        "    \"\"\"Project onto Poincaré ball.\"\"\"\n",
        "    normx = torch.norm(x, p=2, dim=-1, keepdim=True)\n",
        "    maxnorm = (1 - 1e-5) / torch.sqrt(k)\n",
        "    cond = normx > maxnorm\n",
        "    projected = x / normx * maxnorm\n",
        "    return torch.where(cond, projected, x)\n",
        "\n",
        "########################\n",
        "# Hyperbolic Linear Layer\n",
        "########################\n",
        "\n",
        "class HypLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, k):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.weight = nn.Parameter(torch.randn(in_features, out_features)*0.01)\n",
        "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_tan = logmap0(x, self.k)\n",
        "        out = x_tan @ self.weight + self.bias\n",
        "        out_hyp = expmap0(out, self.k)\n",
        "        return projx(out_hyp, self.k)\n",
        "\n",
        "########################\n",
        "# Hyperbolic Graph Convolution Layer\n",
        "########################\n",
        "\n",
        "class HypGraphConvolution(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, curvature):\n",
        "        super().__init__()\n",
        "        self.curvature = curvature\n",
        "        self.hyp_linear = HypLinear(in_dim, out_dim, curvature)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # x: [N, D], adj: [N, N]\n",
        "        # Aggregate neighbors in tangent space\n",
        "        x_tan = logmap0(x, self.curvature)\n",
        "        agg = adj @ x_tan\n",
        "        deg = torch.sum(adj, dim=-1, keepdim=True)\n",
        "        agg = agg / (deg + 1e-15)\n",
        "        agg_hyp = expmap0(agg, self.curvature)\n",
        "        agg_hyp = projx(agg_hyp, self.curvature)\n",
        "\n",
        "        out = self.hyp_linear(agg_hyp)\n",
        "        return projx(out, self.curvature)\n",
        "\n",
        "########################\n",
        "# Simple Model\n",
        "########################\n",
        "\n",
        "class SimpleHGCN(nn.Module):\n",
        "    def __init__(self, num_nodes, in_dim, hidden_dim, curvature):\n",
        "        super().__init__()\n",
        "        self.curvature = curvature\n",
        "        # Initialize embeddings on hyperbolic manifold\n",
        "        self.emb = geoopt.ManifoldParameter(\n",
        "            torch.randn(num_nodes, in_dim)*0.01,\n",
        "            manifold=geoopt.manifolds.PoincareBall()\n",
        "        )\n",
        "        self.gc1 = HypGraphConvolution(in_dim, hidden_dim, curvature)\n",
        "        self.gc2 = HypGraphConvolution(hidden_dim, hidden_dim, curvature)\n",
        "        # A simple classifier:\n",
        "        self.classifier = nn.Linear(hidden_dim, 2)  # Suppose 2-class classification\n",
        "\n",
        "    def forward(self, adj):\n",
        "        x = self.emb\n",
        "        x = self.gc1(x, adj)\n",
        "        x = F.relu(x)\n",
        "        x = self.gc2(x, adj)\n",
        "        x = F.relu(x)\n",
        "        # For classification, map to tangent and do a Euclidean linear:\n",
        "        x_tan = logmap0(x, self.curvature)\n",
        "        logits = self.classifier(x_tan)\n",
        "        return logits\n",
        "\n",
        "########################\n",
        "# Riemannian L-BFGS (Simplified)\n",
        "########################\n",
        "\n",
        "class RiemannianLBFGS(torch.optim.Optimizer):\n",
        "    def __init__(self, params, lr=0.1):\n",
        "        defaults = dict(lr=lr)\n",
        "        super().__init__(params, defaults)\n",
        "        self._params = self.param_groups[0]['params']\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        # This is a simplified LBFGS, essentially doing a gradient step on the manifold\n",
        "        # Real L-BFGS would implement two-loop recursion and history storage.\n",
        "        # Here we just do a Riemannian gradient update for demonstration.\n",
        "\n",
        "        group = self.param_groups[0]\n",
        "        lr = group['lr']\n",
        "\n",
        "        for p in self._params:\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            # Riemannian update:\n",
        "            # geoopt manifold parameters automatically handle projection,\n",
        "            # but we use expmap for clarity\n",
        "            grad = p.grad\n",
        "            # negative gradient direction\n",
        "            update = -lr * grad\n",
        "            # Update parameter using exponential map at p\n",
        "            # If p is manifold parameter with a known manifold and curvature, we must supply k.\n",
        "            # For PoincareBall, we can access p.manifold:\n",
        "            if hasattr(p, 'manifold') and isinstance(p.manifold, geoopt.manifolds.PoincareBall):\n",
        "                # We'll assume curvature = 1.0 if not otherwise specified.\n",
        "                # If curvature is a parameter, we need to retrieve it.\n",
        "                # For simplicity, let's assume we have a global curvature=1.0 or\n",
        "                # store it somewhere accessible.\n",
        "                k = 1.0\n",
        "                p.data = p.manifold.expmap(p.data, update, k=k)\n",
        "            else:\n",
        "                # For Euclidean parameters like classifier weights:\n",
        "                p.add_(update)\n",
        "\n",
        "        return loss\n",
        "\n",
        "########################\n",
        "# Toy Example and Training Loop\n",
        "########################\n",
        "\n",
        "# Create a small toy graph\n",
        "num_nodes = 4\n",
        "in_dim = 4\n",
        "hidden_dim = 8\n",
        "curvature = torch.tensor([1.0])  # fixed curvature\n",
        "\n",
        "# A simple adjacency for a small graph (undirected)\n",
        "adj = torch.tensor([\n",
        "    [0.,1.,0.,0.],\n",
        "    [1.,0.,1.,0.],\n",
        "    [0.,1.,0.,1.],\n",
        "    [0.,0.,1.,0.]\n",
        "])\n",
        "\n",
        "model = SimpleHGCN(num_nodes, in_dim, hidden_dim, curvature)\n",
        "optimizer = RiemannianLBFGS(model.parameters(), lr=0.1)\n",
        "\n",
        "# Suppose we have a toy \"label\" for each node: just random\n",
        "labels = torch.randint(0,2,(num_nodes,))\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(5):\n",
        "    def closure():\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(adj)\n",
        "        # Simple node classification loss\n",
        "        # logits: [N, 2]\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        loss.backward()\n",
        "        return loss\n",
        "\n",
        "    loss = optimizer.step(closure)\n",
        "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QPXkcBtZZdSg",
        "outputId": "86d193ca-9fe6-47fc-d624-abb791c0c7b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geoopt in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from geoopt) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from geoopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from geoopt) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->geoopt) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->geoopt) (3.0.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7e7d7fe877da>\u001b[0m in \u001b[0;36m<cell line: 178>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}, Loss: {loss.item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-7e7d7fe877da>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# This is a simplified LBFGS, essentially doing a gradient step on the manifold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-7e7d7fe877da>\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# logits: [N, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geoopt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O8lq8_4bBgg",
        "outputId": "2dc360ef-98a8-42f2-ace8-d17fd0250ce4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geoopt\n",
            "  Downloading geoopt-0.5.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from geoopt) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from geoopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from geoopt) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->geoopt) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->geoopt) (3.0.2)\n",
            "Downloading geoopt-0.5.0-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: geoopt\n",
            "Successfully installed geoopt-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import geoopt\n",
        "\n",
        "########################\n",
        "# Hyperbolic Utility Functions\n",
        "########################\n",
        "\n",
        "def atanh(x, eps=1e-15):\n",
        "    return 0.5 * torch.log((1 + x)/(1 - x + eps))\n",
        "\n",
        "def expmap0(u, k):\n",
        "    \"\"\"Exponential map at 0 on the Poincaré ball.\"\"\"\n",
        "    normu = torch.clamp_min(torch.norm(u, p=2, dim=-1, keepdim=True), 1e-15)\n",
        "    sqrtk = torch.sqrt(k)\n",
        "    return torch.tanh(sqrtk * normu) * u / (sqrtk * normu)\n",
        "\n",
        "def logmap0(x, k):\n",
        "    \"\"\"Log map at 0 on the Poincaré ball.\"\"\"\n",
        "    normx = torch.clamp_min(torch.norm(x, p=2, dim=-1, keepdim=True), 1e-15)\n",
        "    sqrtk = torch.sqrt(k)\n",
        "    return (1./sqrtk) * atanh(sqrtk * normx) * x / normx\n",
        "\n",
        "def projx(x, k):\n",
        "    \"\"\"Project onto Poincaré ball.\"\"\"\n",
        "    normx = torch.norm(x, p=2, dim=-1, keepdim=True)\n",
        "    maxnorm = (1 - 1e-5) / torch.sqrt(k)\n",
        "    cond = normx > maxnorm\n",
        "    projected = x / normx * maxnorm\n",
        "    return torch.where(cond, projected, x)\n"
      ],
      "metadata": {
        "id": "AGxMNOlfZ7DL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HypLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, k):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.weight = nn.Parameter(torch.randn(in_features, out_features) * 0.01)\n",
        "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_tan = logmap0(x, self.k)\n",
        "        out = x_tan @ self.weight + self.bias\n",
        "        out_hyp = expmap0(out, self.k)\n",
        "        return projx(out_hyp, self.k)\n"
      ],
      "metadata": {
        "id": "_l8JZcRiaXy5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HypGraphConvolution(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, curvature):\n",
        "        super().__init__()\n",
        "        self.curvature = curvature\n",
        "        self.hyp_linear = HypLinear(in_dim, out_dim, curvature)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # x: [N, D], adj: [N, N]\n",
        "        # Aggregate neighbors in tangent space\n",
        "        x_tan = logmap0(x, self.curvature)\n",
        "        agg = adj @ x_tan\n",
        "        deg = torch.sum(adj, dim=-1, keepdim=True)\n",
        "        agg = agg / (deg + 1e-15)\n",
        "        agg_hyp = expmap0(agg, self.curvature)\n",
        "        agg_hyp = projx(agg_hyp, self.curvature)\n",
        "\n",
        "        out = self.hyp_linear(agg_hyp)\n",
        "        return projx(out, self.curvature)\n"
      ],
      "metadata": {
        "id": "Z5gXgoKIaZGk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleHGCN(nn.Module):\n",
        "    def __init__(self, num_nodes, in_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        # Learnable curvature parameter (optional)\n",
        "        # If you want curvature to be learnable, uncomment the following line:\n",
        "        self.curvature = torch.nn.Parameter(torch.tensor([1.0]), requires_grad=True).to('cuda')\n",
        "        # For simplicity, we'll fix curvature to 1.0\n",
        "        # self.curvature = torch.tensor([-1], requires_grad=False).to('cuda')\n",
        "\n",
        "        # Initialize embeddings on hyperbolic manifold\n",
        "        self.emb = geoopt.ManifoldParameter(\n",
        "            torch.randn(num_nodes, in_dim) * 0.01,\n",
        "            manifold=geoopt.manifolds.PoincareBall()\n",
        "        )\n",
        "\n",
        "        self.gc1 = HypGraphConvolution(in_dim, hidden_dim, self.curvature)\n",
        "        self.gc2 = HypGraphConvolution(hidden_dim, hidden_dim, self.curvature)\n",
        "\n",
        "        # A simple classifier:\n",
        "        self.classifier = nn.Linear(hidden_dim, 2)  # 2-class classification\n",
        "\n",
        "    def forward(self, adj):\n",
        "        x = self.emb\n",
        "        x = self.gc1(x, adj)\n",
        "        x = F.relu(x)\n",
        "        x = self.gc2(x, adj)\n",
        "        x = F.relu(x)\n",
        "        # For classification, map to tangent and do a Euclidean linear:\n",
        "        x_tan = logmap0(x, self.curvature)\n",
        "        logits = self.classifier(x_tan)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "HYr7I1FwaaTq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a small toy graph\n",
        "num_nodes = 4\n",
        "in_dim = 4\n",
        "hidden_dim = 8\n",
        "\n",
        "\n",
        "# A simple adjacency for a small undirected graph\n",
        "adj = torch.tensor([\n",
        "    [0., 1., 0., 0.],\n",
        "    [1., 0., 1., 0.],\n",
        "    [0., 1., 0., 1.],\n",
        "    [0., 0., 1., 0.]\n",
        "])\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "adj = adj.to(device)\n",
        "\n",
        "# Initialize model and move to device\n",
        "model = SimpleHGCN(num_nodes, in_dim, hidden_dim).to(device)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = geoopt.optim.RiemannianAdam(model.parameters(), lr=0.1)\n",
        "\n",
        "# Define labels for node classification (random for demonstration)\n",
        "labels = torch.randint(0, 2, (num_nodes,)).to(device)\n"
      ],
      "metadata": {
        "id": "Iom8OKUWabVH"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "model.train()\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    def closure():\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(adj)\n",
        "        # Simple node classification loss\n",
        "        # logits: [N, 2]\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        loss.backward()\n",
        "        return loss\n",
        "\n",
        "    loss = optimizer.step(closure)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWNeT1h5acwa",
        "outputId": "e01417c4-b2be-4e80-c6d2-b60bcaebac5f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 0.8143\n",
            "Epoch 2/100, Loss: 0.7427\n",
            "Epoch 3/100, Loss: 0.6596\n",
            "Epoch 4/100, Loss: 0.5850\n",
            "Epoch 5/100, Loss: 0.5581\n",
            "Epoch 6/100, Loss: 0.5890\n",
            "Epoch 7/100, Loss: 0.5661\n",
            "Epoch 8/100, Loss: 0.5397\n",
            "Epoch 9/100, Loss: 0.5250\n",
            "Epoch 10/100, Loss: 0.5093\n",
            "Epoch 11/100, Loss: 0.4852\n",
            "Epoch 12/100, Loss: nan\n",
            "Epoch 13/100, Loss: nan\n",
            "Epoch 14/100, Loss: nan\n",
            "Epoch 15/100, Loss: nan\n",
            "Epoch 16/100, Loss: nan\n",
            "Epoch 17/100, Loss: nan\n",
            "Epoch 18/100, Loss: nan\n",
            "Epoch 19/100, Loss: nan\n",
            "Epoch 20/100, Loss: nan\n",
            "Epoch 21/100, Loss: nan\n",
            "Epoch 22/100, Loss: nan\n",
            "Epoch 23/100, Loss: nan\n",
            "Epoch 24/100, Loss: nan\n",
            "Epoch 25/100, Loss: nan\n",
            "Epoch 26/100, Loss: nan\n",
            "Epoch 27/100, Loss: nan\n",
            "Epoch 28/100, Loss: nan\n",
            "Epoch 29/100, Loss: nan\n",
            "Epoch 30/100, Loss: nan\n",
            "Epoch 31/100, Loss: nan\n",
            "Epoch 32/100, Loss: nan\n",
            "Epoch 33/100, Loss: nan\n",
            "Epoch 34/100, Loss: nan\n",
            "Epoch 35/100, Loss: nan\n",
            "Epoch 36/100, Loss: nan\n",
            "Epoch 37/100, Loss: nan\n",
            "Epoch 38/100, Loss: nan\n",
            "Epoch 39/100, Loss: nan\n",
            "Epoch 40/100, Loss: nan\n",
            "Epoch 41/100, Loss: nan\n",
            "Epoch 42/100, Loss: nan\n",
            "Epoch 43/100, Loss: nan\n",
            "Epoch 44/100, Loss: nan\n",
            "Epoch 45/100, Loss: nan\n",
            "Epoch 46/100, Loss: nan\n",
            "Epoch 47/100, Loss: nan\n",
            "Epoch 48/100, Loss: nan\n",
            "Epoch 49/100, Loss: nan\n",
            "Epoch 50/100, Loss: nan\n",
            "Epoch 51/100, Loss: nan\n",
            "Epoch 52/100, Loss: nan\n",
            "Epoch 53/100, Loss: nan\n",
            "Epoch 54/100, Loss: nan\n",
            "Epoch 55/100, Loss: nan\n",
            "Epoch 56/100, Loss: nan\n",
            "Epoch 57/100, Loss: nan\n",
            "Epoch 58/100, Loss: nan\n",
            "Epoch 59/100, Loss: nan\n",
            "Epoch 60/100, Loss: nan\n",
            "Epoch 61/100, Loss: nan\n",
            "Epoch 62/100, Loss: nan\n",
            "Epoch 63/100, Loss: nan\n",
            "Epoch 64/100, Loss: nan\n",
            "Epoch 65/100, Loss: nan\n",
            "Epoch 66/100, Loss: nan\n",
            "Epoch 67/100, Loss: nan\n",
            "Epoch 68/100, Loss: nan\n",
            "Epoch 69/100, Loss: nan\n",
            "Epoch 70/100, Loss: nan\n",
            "Epoch 71/100, Loss: nan\n",
            "Epoch 72/100, Loss: nan\n",
            "Epoch 73/100, Loss: nan\n",
            "Epoch 74/100, Loss: nan\n",
            "Epoch 75/100, Loss: nan\n",
            "Epoch 76/100, Loss: nan\n",
            "Epoch 77/100, Loss: nan\n",
            "Epoch 78/100, Loss: nan\n",
            "Epoch 79/100, Loss: nan\n",
            "Epoch 80/100, Loss: nan\n",
            "Epoch 81/100, Loss: nan\n",
            "Epoch 82/100, Loss: nan\n",
            "Epoch 83/100, Loss: nan\n",
            "Epoch 84/100, Loss: nan\n",
            "Epoch 85/100, Loss: nan\n",
            "Epoch 86/100, Loss: nan\n",
            "Epoch 87/100, Loss: nan\n",
            "Epoch 88/100, Loss: nan\n",
            "Epoch 89/100, Loss: nan\n",
            "Epoch 90/100, Loss: nan\n",
            "Epoch 91/100, Loss: nan\n",
            "Epoch 92/100, Loss: nan\n",
            "Epoch 93/100, Loss: nan\n",
            "Epoch 94/100, Loss: nan\n",
            "Epoch 95/100, Loss: nan\n",
            "Epoch 96/100, Loss: nan\n",
            "Epoch 97/100, Loss: nan\n",
            "Epoch 98/100, Loss: nan\n",
            "Epoch 99/100, Loss: nan\n",
            "Epoch 100/100, Loss: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geoopt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEmMIc0i7sQk",
        "outputId": "8d2c1bc4-b728-42f9-ae06-c9b36e715745"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geoopt\n",
            "  Downloading geoopt-0.5.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from geoopt) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from geoopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from geoopt) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->geoopt) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->geoopt) (3.0.2)\n",
            "Downloading geoopt-0.5.0-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: geoopt\n",
            "Successfully installed geoopt-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "import math\n",
        "from torch import optim\n",
        "import geoopt\n",
        "from geoopt import ManifoldParameter\n",
        "\n",
        "##############################################\n",
        "# Data Loading and Preprocessing\n",
        "##############################################\n",
        "\n",
        "def load_fb15k_data(train_path, valid_path, test_path):\n",
        "    # FB15K format: head \\t relation \\t tail\n",
        "    # Build dictionaries for entities and relations\n",
        "    # Returns: node2id, rel2id, edge_list, and a graph\n",
        "    def read_triples(path, ent2id, rel2id):\n",
        "        triples = []\n",
        "        with open(path, 'r') as f:\n",
        "            for line in f:\n",
        "                h, r, t = line.strip().split('\\t')\n",
        "                if h not in ent2id:\n",
        "                    ent2id[h] = len(ent2id)\n",
        "                if t not in ent2id:\n",
        "                    ent2id[t] = len(ent2id)\n",
        "                if r not in rel2id:\n",
        "                    rel2id[r] = len(rel2id)\n",
        "                triples.append((h, r, t))\n",
        "        return triples\n",
        "\n",
        "    ent2id = {}\n",
        "    rel2id = {}\n",
        "    train_triples = read_triples(train_path, ent2id, rel2id)\n",
        "    valid_triples = read_triples(valid_path, ent2id, rel2id)\n",
        "    test_triples = read_triples(test_path, ent2id, rel2id)\n",
        "\n",
        "    # Build adjacency (undirected for GCN)\n",
        "    G = nx.Graph()\n",
        "    G.add_nodes_from(range(len(ent2id)))\n",
        "    for h, r, t in train_triples:\n",
        "        G.add_edge(ent2id[h], ent2id[t])\n",
        "\n",
        "    return ent2id, rel2id, G, train_triples, valid_triples, test_triples\n",
        "\n",
        "# Example paths (replace with your actual paths)\n",
        "train_path = 'train.txt'\n",
        "valid_path = 'valid.txt'\n",
        "test_path = 'test.txt'\n",
        "\n",
        "ent2id, rel2id, G, train_triples, valid_triples, test_triples = load_fb15k_data(train_path, valid_path, test_path)\n",
        "\n",
        "num_nodes = len(ent2id)\n",
        "adj = nx.to_scipy_sparse_array(G, nodelist=range(num_nodes))\n",
        "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)  # symmetrize\n",
        "adj = torch.tensor(adj.toarray(), dtype=torch.float32) + 1e-5*torch.eye(num_nodes)\n",
        "degrees = adj.sum(axis=1)\n",
        "inv_sqrt_deg = 1. / torch.sqrt(degrees)\n",
        "inv_sqrt_deg[torch.isinf(inv_sqrt_deg)] = 0\n",
        "D_inv_sqrt = torch.diag(inv_sqrt_deg)\n",
        "norm_adj = torch.tensor(D_inv_sqrt @ adj @ D_inv_sqrt, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# For simplicity, let's do a fake node classification target:\n",
        "# Assign random labels to nodes (in practice, you would use a known node classification split)\n",
        "num_classes = 5\n",
        "labels = torch.randint(0, num_classes, (num_nodes,))\n",
        "\n",
        "# Features: Let's just initialize random features or identity\n",
        "# In a real scenario, you'd have meaningful features\n",
        "features = torch.eye(num_nodes)\n",
        "\n",
        "##############################################\n",
        "# Manifold and Hyperbolic Layers\n",
        "##############################################\n",
        "\n",
        "class HyperbolicLinear(nn.Module):\n",
        "    \"\"\"\n",
        "    Hyperbolic linear layer: maps from Poincaré ball to tangent space,\n",
        "    applies a linear transform, then maps back.\n",
        "    \"\"\"\n",
        "    def __init__(self, manifold, in_features, out_features, c=1.0, bias=True):\n",
        "        super(HyperbolicLinear, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = ManifoldParameter(torch.randn(out_features, in_features)*0.01, manifold=self.manifold)\n",
        "        self.c = c\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is on manifold\n",
        "        # Move x to tangent space at 0\n",
        "        tangent_x = self.manifold.logmap0(x, k=self.c)\n",
        "        # Apply linear transform in tangent space\n",
        "        out = F.linear(tangent_x, self.weight, self.bias)\n",
        "        # Map back to manifold\n",
        "        out = self.manifold.expmap0(out, k=self.c)\n",
        "        return out\n",
        "\n",
        "\n",
        "class HyperbolicGCNLayer(nn.Module):\n",
        "    def __init__(self, manifold, in_features, out_features, c=1.0):\n",
        "        super(HyperbolicGCNLayer, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.lin = HyperbolicLinear(manifold, in_features, out_features, c=c)\n",
        "        self.c = c\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # x on Poincaré ball\n",
        "        # Compute neighbor aggregation in tangent space\n",
        "        # First map x to tangent at 0\n",
        "        x_tan = self.manifold.logmap0(x)\n",
        "        # Aggregate using normalized adjacency (like Euclidean GCN, but in tangent space)\n",
        "        x_agg = adj @ x_tan\n",
        "        # Map back to manifold (we can combine with linear)\n",
        "        x_agg = self.manifold.expmap0(x_agg)\n",
        "        # Apply hyperbolic linear layer\n",
        "        x_out = self.lin(x_agg)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class HyperbolicGCN(nn.Module):\n",
        "    def __init__(self, manifold, num_features, hidden_dim, num_classes, c=1.0):\n",
        "        super(HyperbolicGCN, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.layer1 = HyperbolicGCNLayer(manifold, num_features, hidden_dim, c=c)\n",
        "        self.layer2 = HyperbolicGCNLayer(manifold, hidden_dim, num_classes, c=c)\n",
        "        self.c = c\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.manifold.expmap0(x, k=self.c)  # ensure x is on the manifold\n",
        "        x = self.layer1(x, adj)\n",
        "        # Apply a hyperbolic nonlinearity, e.g. hyperbolic tangent\n",
        "        x_tan = self.manifold.logmap0(x, k=self.c)\n",
        "        x_tan = torch.tanh(x_tan)\n",
        "        x = self.manifold.expmap0(x_tan, k=self.c)\n",
        "        x = self.layer2(x, adj)\n",
        "        return x\n",
        "\n",
        "\n",
        "##############################################\n",
        "# Riemannian L-BFGS Optimizer\n",
        "##############################################\n",
        "class RiemannianLBFGS(optim.Optimizer):\n",
        "    \"\"\"\n",
        "    A very basic Riemannian L-BFGS implementation.\n",
        "    This is a conceptual template and may need refinement.\n",
        "\n",
        "    Arguments:\n",
        "        params (iterable): iterable of parameters to optimize\n",
        "        lr (float): learning rate (step size)\n",
        "        history_size (int): L-BFGS memory size\n",
        "        line_search_fn (str): line search to use\n",
        "        c (float): curvature parameter for manifold\n",
        "    \"\"\"\n",
        "    def __init__(self, params, lr=1.0, history_size=10, c=1.0):\n",
        "        defaults = dict(lr=lr, history_size=history_size, c=c)\n",
        "        super(RiemannianLBFGS, self).__init__(params, defaults)\n",
        "        # Store previous updates\n",
        "        for group in self.param_groups:\n",
        "            group['s_history'] = []\n",
        "            group['y_history'] = []\n",
        "            group['rho_history'] = []\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        # closure is a function that re-evaluates the model and returns the loss.\n",
        "        # 1) Evaluate loss and gradients if needed\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        # Collect flatten gradients and parameters on tangent space\n",
        "        for group in self.param_groups:\n",
        "            manifold = None\n",
        "            for p in group['params']:\n",
        "                if hasattr(p, 'manifold'):\n",
        "                    manifold = p.manifold\n",
        "                    break\n",
        "            if manifold is None:\n",
        "                raise ValueError(\"No manifold found in parameters\")\n",
        "\n",
        "            lr = group['lr']\n",
        "            s_history = group['s_history']\n",
        "            y_history = group['y_history']\n",
        "            rho_history = group['rho_history']\n",
        "            history_size = group['history_size']\n",
        "            c = group['c']\n",
        "\n",
        "            # Flatten gradients and parameters\n",
        "            grads = []\n",
        "            params_flat = []\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                # Riemannian gradient is already p.grad on tangent space after backward with geoopt?\n",
        "                # If not, you may need to project Euclidean gradients to tangent space:\n",
        "                # p.grad = p.manifold.egrad2rgrad(p, p.grad, c=c)\n",
        "                p.grad = p.manifold.egrad2rgrad(p, p.grad, c=c)\n",
        "                grads.append(p.grad.view(-1))\n",
        "                params_flat.append(p.data.view(-1))\n",
        "            grad = torch.cat(grads)\n",
        "            # Initial direction: -grad\n",
        "            direction = -grad\n",
        "\n",
        "            # Two-loop recursion for L-BFGS\n",
        "            if len(s_history) > 0:\n",
        "                # Apply L-BFGS preconditioning\n",
        "                alpha = []\n",
        "                q = grad.clone()\n",
        "                for (s, y, rho) in reversed(list(zip(s_history, y_history, rho_history))):\n",
        "                    alpha_i = rho * torch.dot(s, q)\n",
        "                    q = q - alpha_i * y\n",
        "                    alpha.append(alpha_i)\n",
        "                # scaling by H0 (initial Hessian approx)\n",
        "                # Typically H0 = (s_{k-1}^T y_{k-1}) / (y_{k-1}^T y_{k-1})\n",
        "                # if none available, scale by 1\n",
        "                if len(y_history) > 0:\n",
        "                    y_last = y_history[-1]\n",
        "                    s_last = s_history[-1]\n",
        "                    gamma = torch.dot(s_last, y_last) / torch.dot(y_last, y_last)\n",
        "                else:\n",
        "                    gamma = 1.0\n",
        "                r = gamma * q\n",
        "                # second loop\n",
        "                for (s, y, rho, alpha_i) in zip(s_history, y_history, rho_history, reversed(alpha)):\n",
        "                    beta = rho * torch.dot(y, r)\n",
        "                    r = r + s * (alpha_i - beta)\n",
        "                direction = -r\n",
        "\n",
        "            # Line search not implemented here (fixed step size for demo)\n",
        "            # Update parameters using the exponential map\n",
        "            start_params = torch.cat([p.data.view(-1) for p in group['params']])\n",
        "            for p in group['params']:\n",
        "                sz = p.numel()\n",
        "                dp = direction[:sz].view_as(p.data)\n",
        "                direction = direction[sz:]\n",
        "                # Move along geodesic\n",
        "                # x_{new} = exp_{x}(dp)\n",
        "                # Here dp is in tangent space at p, so:\n",
        "                p.data = p.manifold.expmap(p.data, dp, c=c)\n",
        "\n",
        "            # After the update, we need to compute s and y for next iteration\n",
        "            end_params = torch.cat([p.data.view(-1) for p in group['params']])\n",
        "            s_k = (end_params - start_params).detach()\n",
        "            # y_k = grad_{new} - grad_{old}, we need new grad\n",
        "            # Re-compute gradient after update\n",
        "            # This might be expensive for large problems - normally you have closure\n",
        "            if closure is not None:\n",
        "                new_loss = closure()\n",
        "            else:\n",
        "                # You should have a way to recompute loss and grad here\n",
        "                new_loss = None\n",
        "                # For simplicity, assume we can call backward again with stored graph (not always possible)\n",
        "                # In a production code, store model forward pass in closure\n",
        "            new_grads = []\n",
        "            for p in group['params']:\n",
        "                if p.grad is not None:\n",
        "                    new_grads.append(p.grad.view(-1))\n",
        "            new_grad = torch.cat(new_grads)\n",
        "\n",
        "            y_k = (new_grad - grad).detach()\n",
        "\n",
        "            # Update histories\n",
        "            s_history.insert(0, s_k)\n",
        "            y_history.insert(0, y_k)\n",
        "            rho = 1.0 / torch.dot(y_k, s_k)\n",
        "            rho_history.insert(0, rho)\n",
        "\n",
        "            if len(s_history) > history_size:\n",
        "                s_history.pop()\n",
        "                y_history.pop()\n",
        "                rho_history.pop()\n",
        "\n",
        "        return loss\n",
        "\n",
        "##############################################\n",
        "# Training\n",
        "##############################################\n",
        "\n",
        "device = torch.device(\"cuda\")  # or \"cuda\" if available\n",
        "\n",
        "manifold = geoopt.manifolds.PoincareBall()\n",
        "model = HyperbolicGCN(manifold, num_features=num_nodes, hidden_dim=64, num_classes=num_classes, c=1.0).to(device)\n",
        "\n",
        "# Initialize features as points on manifold:\n",
        "# Start from Euclidean points and map to manifold\n",
        "x = features.to(device)\n",
        "x = manifold.expmap(x, c=1.0)\n",
        "\n",
        "labels = labels.to(device)\n",
        "adj_t = norm_adj.to(device)\n",
        "\n",
        "# Define a simple cross-entropy loss for node classification\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def closure():\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(x, adj_t)\n",
        "    # For node classification: logits shape [N, num_classes]\n",
        "    loss = criterion(logits, labels)\n",
        "    loss.backward()\n",
        "    return loss\n",
        "\n",
        "optimizer = RiemannianLBFGS(model.parameters(), lr=0.5, history_size=10, c=1.0)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(20):\n",
        "    loss = optimizer.step(closure)\n",
        "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "6_xP88NYaepc",
        "outputId": "ef39a1e4-d564-4591-d22e-e0001195097d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-02a3bb11f621>:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  norm_adj = torch.tensor(D_inv_sqrt @ adj @ D_inv_sqrt, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Stereographic.expmap() got an unexpected keyword argument 'c'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-02a3bb11f621>\u001b[0m in \u001b[0;36m<cell line: 292>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;31m# Start from Euclidean points and map to manifold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanifold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Stereographic.expmap() got an unexpected keyword argument 'c'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "from torch import optim\n",
        "import geoopt\n",
        "from geoopt import ManifoldParameter\n",
        "\n",
        "##############################################\n",
        "# Data Loading (Example)\n",
        "##############################################\n",
        "\n",
        "def load_fb15k_data(train_path, valid_path, test_path):\n",
        "    def read_triples(path, ent2id, rel2id):\n",
        "        triples = []\n",
        "        with open(path, 'r') as f:\n",
        "            for line in f:\n",
        "                h, r, t = line.strip().split('\\t')\n",
        "                if h not in ent2id:\n",
        "                    ent2id[h] = len(ent2id)\n",
        "                if t not in ent2id:\n",
        "                    ent2id[t] = len(ent2id)\n",
        "                if r not in rel2id:\n",
        "                    rel2id[r] = len(rel2id)\n",
        "                triples.append((h, r, t))\n",
        "        return triples\n",
        "\n",
        "    ent2id = {}\n",
        "    rel2id = {}\n",
        "    train_triples = read_triples(train_path, ent2id, rel2id)\n",
        "    valid_triples = read_triples(valid_path, ent2id, rel2id)\n",
        "    test_triples = read_triples(test_path, ent2id, rel2id)\n",
        "\n",
        "    G = nx.Graph()\n",
        "    G.add_nodes_from(range(len(ent2id)))\n",
        "    for h, r, t in train_triples:\n",
        "        G.add_edge(ent2id[h], ent2id[t])\n",
        "\n",
        "    return ent2id, rel2id, G, train_triples, valid_triples, test_triples\n",
        "\n",
        "# Example paths (You must provide actual paths)\n",
        "train_path = 'train.txt'\n",
        "valid_path = 'valid.txt'\n",
        "test_path = 'test.txt'\n",
        "\n",
        "ent2id, rel2id, G, train_triples, valid_triples, test_triples = load_fb15k_data(train_path, valid_path, test_path)\n",
        "\n",
        "num_nodes = len(ent2id)\n",
        "adj = nx.to_scipy_sparse_array(G, nodelist=range(num_nodes))\n",
        "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)  # symmetrize\n",
        "adj = torch.tensor(adj.toarray(), dtype=torch.float32) + 1e-5*torch.eye(num_nodes)\n",
        "degrees = adj.sum(axis=1)\n",
        "inv_sqrt_deg = 1. / torch.sqrt(degrees)\n",
        "inv_sqrt_deg[torch.isinf(inv_sqrt_deg)] = 0\n",
        "D_inv_sqrt = torch.diag(inv_sqrt_deg)\n",
        "norm_adj = torch.tensor(D_inv_sqrt @ adj @ D_inv_sqrt, dtype=torch.float32)\n",
        "\n",
        "# Synthetic labels for demonstration (e.g., node classification)\n",
        "num_classes = 5\n",
        "labels = torch.randint(0, num_classes, (num_nodes,))\n",
        "\n",
        "# Features: using identity for simplicity\n",
        "features = torch.eye(num_nodes)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "features, labels, norm_adj = features.to(device), labels.to(device), norm_adj.to(device)\n",
        "\n",
        "##############################################\n",
        "# Hyperbolic GCN Layers\n",
        "##############################################\n",
        "\n",
        "class HyperbolicLinear(nn.Module):\n",
        "    \"\"\"\n",
        "    Hyperbolic linear layer using the Poincaré Ball model.\n",
        "    \"\"\"\n",
        "    def __init__(self, manifold, in_features, out_features, c=1.0, bias=True):\n",
        "        super(HyperbolicLinear, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.c = c\n",
        "        # ManifoldParameter ensures the parameter stays on the manifold\n",
        "        # Here weight is in tangent space initially; we keep it Euclidean and apply expmap0 as needed.\n",
        "        self.weight = ManifoldParameter(torch.randn(out_features, in_features)*0.01, manifold=geoopt.Euclidean())\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is on manifold. We first map to tangent space at 0, apply linear, then map back.\n",
        "        x_tan = self.manifold.logmap0(x, dim=-1)\n",
        "        out = F.linear(x_tan, self.weight, self.bias)\n",
        "        out = self.manifold.expmap0(out, dim=-1)\n",
        "        return out\n",
        "\n",
        "\n",
        "class HyperbolicGCNLayer(nn.Module):\n",
        "    def __init__(self, manifold, in_features, out_features, c=1.0):\n",
        "        super(HyperbolicGCNLayer, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.lin = HyperbolicLinear(manifold, in_features, out_features, c=c)\n",
        "        self.c = c\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # x on manifold.\n",
        "        # Aggregate neighbors in tangent space:\n",
        "        x_tan = self.manifold.logmap0(x, dim=-1)\n",
        "        x_agg_tan = adj @ x_tan  # linear combination in tangent space\n",
        "        x_agg = self.manifold.expmap0(x_agg_tan, dim=-1)\n",
        "        # Apply hyperbolic linear\n",
        "        return self.lin(x_agg)\n",
        "\n",
        "\n",
        "class HyperbolicGCN(nn.Module):\n",
        "    def __init__(self, manifold, num_features, hidden_dim, num_classes, c=1.0):\n",
        "        super(HyperbolicGCN, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.c = c\n",
        "        self.layer1 = HyperbolicGCNLayer(manifold, num_features, hidden_dim, c=c)\n",
        "        self.layer2 = HyperbolicGCNLayer(manifold, hidden_dim, num_classes, c=c)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.manifold.expmap0(x, dim=-1)  # ensure x is on manifold\n",
        "        x = self.layer1(x, adj)\n",
        "        # Hyperbolic activation: apply tanh in tangent space\n",
        "        x_tan = self.manifold.logmap0(x, dim=-1)\n",
        "        x_tan = torch.tanh(x_tan)\n",
        "        x = self.manifold.expmap0(x_tan, dim=-1)\n",
        "        x = self.layer2(x, adj)\n",
        "        return x\n",
        "\n",
        "\n",
        "##############################################\n",
        "# Custom Riemannian L-BFGS\n",
        "##############################################\n",
        "\n",
        "class RiemannianLBFGS(optim.Optimizer):\n",
        "    \"\"\"\n",
        "    A conceptual Riemannian L-BFGS optimizer using geoopt.\n",
        "    \"\"\"\n",
        "    def __init__(self, params, lr=1.0, history_size=10, c=1.0):\n",
        "        defaults = dict(lr=lr, history_size=history_size, c=c)\n",
        "        super(RiemannianLBFGS, self).__init__(params, defaults)\n",
        "        for group in self.param_groups:\n",
        "            group['s_history'] = []\n",
        "            group['y_history'] = []\n",
        "            group['rho_history'] = []\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            c = group['c']\n",
        "            lr = group['lr']\n",
        "            s_history = group['s_history']\n",
        "            y_history = group['y_history']\n",
        "            rho_history = group['rho_history']\n",
        "            history_size = group['history_size']\n",
        "\n",
        "            # Gather parameters and gradients\n",
        "            params_data = []\n",
        "            grads = []\n",
        "            manifolds = []\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                x = p.data\n",
        "                # Convert Euclidean grad to Riemannian grad\n",
        "                # egrad2rgrad requires point on manifold and Euclidean grad\n",
        "                # If p is a ManifoldParameter, p.manifold is the associated manifold\n",
        "                # If no manifold is set for param, assume Euclidean\n",
        "                m = getattr(p, 'manifold', geoopt.Euclidean())\n",
        "                manifolds.append((p, m))\n",
        "                p.grad = m.egrad2rgrad(x, p.grad)  # Riemannian gradient\n",
        "                params_data.append(x.view(-1))\n",
        "                grads.append(p.grad.view(-1))\n",
        "            if len(grads) == 0:\n",
        "                continue\n",
        "            flat_params = torch.cat(params_data)\n",
        "            grad = torch.cat(grads)\n",
        "\n",
        "            # Initial direction is -grad\n",
        "            direction = -grad.clone()\n",
        "\n",
        "            # Two-loop recursion if we have history\n",
        "            if len(s_history) > 0:\n",
        "                alpha = []\n",
        "                q = grad.clone()\n",
        "                for (s, y, rho) in reversed(list(zip(s_history, y_history, rho_history))):\n",
        "                    alpha_i = rho * torch.dot(s, q)\n",
        "                    q = q - alpha_i * y\n",
        "                    alpha.append(alpha_i)\n",
        "                # Scale by H0\n",
        "                if len(y_history) > 0:\n",
        "                    y_last = y_history[-1]\n",
        "                    s_last = s_history[-1]\n",
        "                    gamma = torch.dot(s_last, y_last) / torch.dot(y_last, y_last)\n",
        "                else:\n",
        "                    gamma = 1.0\n",
        "                r = gamma * q\n",
        "                for (s, y, rho, alpha_i) in zip(s_history, y_history, rho_history, reversed(alpha)):\n",
        "                    beta = rho * torch.dot(y, r)\n",
        "                    r = r + s * (alpha_i - beta)\n",
        "                direction = -r\n",
        "\n",
        "            # Update parameters on the manifold\n",
        "            start_params = flat_params\n",
        "            offset = 0\n",
        "            for (p, m) in manifolds:\n",
        "                sz = p.numel()\n",
        "                dp = direction[offset:offset+sz].view_as(p.data)\n",
        "                offset += sz\n",
        "                # Move along geodesic using expmap\n",
        "                # p_new = expmap_x(u), where x = p.data and u = dp is tangent vector\n",
        "                # dp must be projected onto tangent space first\n",
        "                dp = m.proju(p.data, dp)\n",
        "                p.data = m.expmap(p.data, dp)  # Move p along dp\n",
        "\n",
        "            # Recompute gradients for y calculation\n",
        "            new_grads = []\n",
        "            if closure is not None:\n",
        "                new_loss = closure()\n",
        "            else:\n",
        "                # If no closure, we assume no update of s,y.\n",
        "                # In practice, you must provide a closure for LBFGS\n",
        "                new_loss = None\n",
        "\n",
        "            offset = 0\n",
        "            for (p, m) in manifolds:\n",
        "                if p.grad is None:\n",
        "                    # If no grad, can't form y\n",
        "                    continue\n",
        "                new_grads.append(p.grad.view(-1))\n",
        "            if len(new_grads) == 0:\n",
        "                continue\n",
        "            new_grad = torch.cat(new_grads)\n",
        "\n",
        "            end_params = torch.cat([p.data.view(-1) for (p,m) in manifolds])\n",
        "            s_k = (end_params - start_params).detach()\n",
        "            y_k = (new_grad - grad).detach()\n",
        "\n",
        "            # Update histories\n",
        "            s_history.insert(0, s_k)\n",
        "            y_history.insert(0, y_k)\n",
        "            rho = 1.0 / torch.dot(y_k, s_k)\n",
        "            rho_history.insert(0, rho)\n",
        "            if len(s_history) > history_size:\n",
        "                s_history.pop()\n",
        "                y_history.pop()\n",
        "                rho_history.pop()\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "##############################################\n",
        "# Model and Training\n",
        "##############################################\n",
        "\n",
        "manifold = geoopt.manifolds.PoincareBall(c=1.0)\n",
        "\n",
        "model = HyperbolicGCN(manifold, num_features=num_nodes, hidden_dim=64, num_classes=num_classes, c=1.0).to(device)\n",
        "\n",
        "# Initialize input in tangent space and map to manifold\n",
        "x = manifold.expmap0(features, dim=-1)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def closure():\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(x, norm_adj)\n",
        "    loss = criterion(logits, labels)\n",
        "    loss.backward()\n",
        "    return loss\n",
        "\n",
        "optimizer = RiemannianLBFGS(model.parameters(), lr=0.5, history_size=10, c=1.0)\n",
        "\n",
        "for epoch in range(10):\n",
        "    loss = optimizer.step(closure)\n",
        "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBF0Hfy47qOh",
        "outputId": "fe939324-d484-422c-e4c8-6b02d394a477"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b1425d37635a>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  norm_adj = torch.tensor(D_inv_sqrt @ adj @ D_inv_sqrt, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.6094367504119873\n",
            "Epoch 1, Loss: 1.6094053983688354\n",
            "Epoch 2, Loss: 1.6093485355377197\n",
            "Epoch 3, Loss: 1.6093485355377197\n",
            "Epoch 4, Loss: 1.6093387603759766\n",
            "Epoch 5, Loss: 1.609322190284729\n",
            "Epoch 6, Loss: 1.6093178987503052\n",
            "Epoch 7, Loss: 1.6093202829360962\n",
            "Epoch 8, Loss: 1.609328031539917\n",
            "Epoch 9, Loss: 1.6093600988388062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szRA3h-6_aTc",
        "outputId": "19c3300f-35cd-4177-ff42-22101ba4f0c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'torch.version' from '/usr/local/lib/python3.10/dist-packages/torch/version.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "from torch import optim\n",
        "import geoopt\n",
        "from geoopt import ManifoldParameter\n",
        "\n",
        "# Assuming you've loaded FB15K data into train_triples, etc.\n",
        "# and built norm_adj and features as before.\n",
        "\n",
        "class HyperbolicLinear(nn.Module):\n",
        "    def __init__(self, manifold, in_features, out_features, bias=True):\n",
        "        super(HyperbolicLinear, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = ManifoldParameter(torch.randn(out_features, in_features)*0.01, manifold=geoopt.Euclidean())\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_tan = self.manifold.logmap0(x, dim=-1)\n",
        "        out = F.linear(x_tan, self.weight, self.bias)\n",
        "        out = self.manifold.expmap0(out, dim=-1)\n",
        "        return out\n",
        "\n",
        "class HyperbolicGCNLayer(nn.Module):\n",
        "    def __init__(self, manifold, in_features, out_features):\n",
        "        super(HyperbolicGCNLayer, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.lin = HyperbolicLinear(manifold, in_features, out_features)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x_tan = self.manifold.logmap0(x, dim=-1)\n",
        "        x_agg_tan = adj @ x_tan\n",
        "        x_agg = self.manifold.expmap0(x_agg_tan, dim=-1)\n",
        "        return self.lin(x_agg)\n",
        "\n",
        "class HyperbolicGCN(nn.Module):\n",
        "    def __init__(self, manifold, num_features, hidden_dim, num_classes):\n",
        "        super(HyperbolicGCN, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.layer1 = HyperbolicGCNLayer(manifold, num_features, hidden_dim)\n",
        "        self.layer2 = HyperbolicGCNLayer(manifold, hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.manifold.expmap0(x, dim=-1)\n",
        "        x = self.layer1(x, adj)\n",
        "        x_tan = self.manifold.logmap0(x, dim=-1)\n",
        "        x_tan = torch.tanh(x_tan)\n",
        "        x = self.manifold.expmap0(x_tan, dim=-1)\n",
        "        x = self.layer2(x, adj)\n",
        "        return x\n",
        "\n",
        "# Make the curvature learnable\n",
        "manifold = geoopt.PoincareBall(c=1.0, learnable=True)\n",
        "\n",
        "model = HyperbolicGCN(manifold, num_features=num_nodes, hidden_dim=64, num_classes=num_classes).to(device)\n",
        "\n",
        "# Initialize input\n",
        "x = manifold.expmap0(features, dim=-1)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def closure():\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(x, norm_adj)\n",
        "    loss = criterion(logits, labels)\n",
        "    loss.backward(retain_graph=True)\n",
        "    return loss\n",
        "\n",
        "# Use a smaller LR, consider using RiemannianAdam for more stability\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(10):\n",
        "    loss = closure()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch}, Loss: {loss.item()}, Curvature: {manifold.c.item()}\")\n",
        "\n",
        "# After training, you can inspect manifold.c to see if curvature adjusted.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "Ok9jbh-GBFUK",
        "outputId": "585715cb-b3f9-458d-d62f-4647cf2c00ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.609438180923462, Curvature: 1.0005226135253906\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor []] is at version 4; expected version 3 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-13117fe63b60>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}, Loss: {loss.item()}, Curvature: {manifold.c.item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-13117fe63b60>\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_adj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor []] is at version 4; expected version 3 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "from torch import optim\n",
        "import geoopt\n",
        "from geoopt import ManifoldParameter\n",
        "\n",
        "##############################################\n",
        "# Data Loading (Example)\n",
        "##############################################\n",
        "\n",
        "def load_fb15k_data(train_path, valid_path, test_path):\n",
        "    def read_triples(path, ent2id, rel2id):\n",
        "        triples = []\n",
        "        with open(path, 'r') as f:\n",
        "            for line in f:\n",
        "                h, r, t = line.strip().split('\\t')\n",
        "                if h not in ent2id:\n",
        "                    ent2id[h] = len(ent2id)\n",
        "                if t not in ent2id:\n",
        "                    ent2id[t] = len(ent2id)\n",
        "                if r not in rel2id:\n",
        "                    rel2id[r] = len(rel2id)\n",
        "                triples.append((ent2id[h], rel2id[r], ent2id[t]))\n",
        "        return triples\n",
        "\n",
        "    ent2id = {}\n",
        "    rel2id = {}\n",
        "    train_triples = read_triples(train_path, ent2id, rel2id)\n",
        "    valid_triples = read_triples(valid_path, ent2id, rel2id)\n",
        "    test_triples = read_triples(test_path, ent2id, rel2id)\n",
        "\n",
        "    G = nx.Graph()\n",
        "    G.add_nodes_from(range(len(ent2id)))\n",
        "    for h, r, t in train_triples:\n",
        "        G.add_edge(h, t)\n",
        "\n",
        "    return ent2id, rel2id, G, train_triples, valid_triples, test_triples\n",
        "\n",
        "# Example paths (You must provide actual paths)\n",
        "train_path = 'train.txt'\n",
        "valid_path = 'valid.txt'\n",
        "test_path = 'test.txt'\n",
        "\n",
        "# For demonstration, create dummy data if files are not available\n",
        "import os\n",
        "if not os.path.exists(train_path):\n",
        "    with open(train_path, 'w') as f:\n",
        "        for i in range(100):\n",
        "            f.write(f\"entity_{i}\\trelation_{i%10}\\tentity_{(i+1)%100}\\n\")\n",
        "    with open(valid_path, 'w') as f:\n",
        "        for i in range(100, 120):\n",
        "            f.write(f\"entity_{i%100}\\trelation_{i%10}\\tentity_{(i+1)%100}\\n\")\n",
        "    with open(test_path, 'w') as f:\n",
        "        for i in range(120, 140):\n",
        "            f.write(f\"entity_{i%100}\\trelation_{i%10}\\tentity_{(i+1)%100}\\n\")\n",
        "\n",
        "ent2id, rel2id, G, train_triples, valid_triples, test_triples = load_fb15k_data(train_path, valid_path, test_path)\n",
        "\n",
        "num_nodes = len(ent2id)\n",
        "num_relations = len(rel2id)\n",
        "\n",
        "adj = nx.to_scipy_sparse_array(G, nodelist=range(num_nodes))\n",
        "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)  # symmetrize\n",
        "adj = torch.tensor(adj.toarray(), dtype=torch.float32) + 1e-5*torch.eye(num_nodes)\n",
        "degrees = adj.sum(axis=1)\n",
        "inv_sqrt_deg = 1. / torch.sqrt(degrees)\n",
        "inv_sqrt_deg[torch.isinf(inv_sqrt_deg)] = 0\n",
        "D_inv_sqrt = torch.diag(inv_sqrt_deg)\n",
        "norm_adj = D_inv_sqrt @ adj @ D_inv_sqrt\n",
        "norm_adj = norm_adj.to(torch.float32)\n",
        "\n",
        "# Node features: using identity for simplicity\n",
        "features = torch.eye(num_nodes, device='cpu')  # Initialize on CPU first\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "features, norm_adj = features.to(device), norm_adj.to(device)\n",
        "\n",
        "##############################################\n",
        "# Hyperbolic GCN Layers\n",
        "##############################################\n",
        "\n",
        "class HyperbolicLinear(nn.Module):\n",
        "    \"\"\"\n",
        "    Hyperbolic linear layer using the Poincaré Ball model.\n",
        "    \"\"\"\n",
        "    def __init__(self, manifold, in_features, out_features, bias=True):\n",
        "        super(HyperbolicLinear, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        # ManifoldParameter for weight in Euclidean space\n",
        "        self.weight = ManifoldParameter(torch.randn(out_features, in_features)*0.01, manifold=geoopt.Euclidean())\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is on manifold. Map to tangent space at 0, apply linear, map back\n",
        "        x_tan = self.manifold.logmap0(x, dim=-1)\n",
        "        out = F.linear(x_tan, self.weight, self.bias)\n",
        "        out = self.manifold.expmap0(out, dim=-1)\n",
        "        return out\n",
        "\n",
        "class HyperbolicGCNLayer(nn.Module):\n",
        "    def __init__(self, manifold, in_features, out_features):\n",
        "        super(HyperbolicGCNLayer, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.lin = HyperbolicLinear(manifold, in_features, out_features)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # x on manifold\n",
        "        x_tan = self.manifold.logmap0(x, dim=-1)\n",
        "        x_agg_tan = adj @ x_tan  # aggregate in tangent space\n",
        "        x_agg = self.manifold.expmap0(x_agg_tan, dim=-1)\n",
        "        return self.lin(x_agg)\n",
        "\n",
        "class HyperbolicGCN(nn.Module):\n",
        "    def __init__(self, manifold, num_features, hidden_dim, num_classes):\n",
        "        super(HyperbolicGCN, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.layer1 = HyperbolicGCNLayer(manifold, num_features, hidden_dim)\n",
        "        self.layer2 = HyperbolicGCNLayer(manifold, hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.manifold.expmap0(x, dim=-1)  # ensure x is on manifold\n",
        "        x = self.layer1(x, adj)\n",
        "        # Hyperbolic activation: apply tanh in tangent space\n",
        "        x_tan = self.manifold.logmap0(x, dim=-1)\n",
        "        x_tan = torch.tanh(x_tan)\n",
        "        x = self.manifold.expmap0(x_tan, dim=-1)\n",
        "        x = self.layer2(x, adj)\n",
        "        return x\n",
        "\n",
        "##############################################\n",
        "# Model and Training\n",
        "##############################################\n",
        "\n",
        "# Make the curvature learnable\n",
        "manifold = geoopt.PoincareBall(c=1.0, learnable=True)\n",
        "\n",
        "model = HyperbolicGCN(manifold, num_features=num_nodes, hidden_dim=64, num_classes=num_relations).to(device)\n",
        "\n",
        "# Initialize input: ensure features are on the manifold\n",
        "x = manifold.expmap0(features, dim=-1)\n",
        "\n",
        "# Define optimizer using Geoopt's RiemannianAdam\n",
        "optimizer = geoopt.optim.RiemannianAdam(\n",
        "    [\n",
        "        {'params': model.parameters()},\n",
        "        {'params': [manifold.c], 'lr': 1e-3}  # Add 'stabilize' with a value\n",
        "    ],\n",
        "    lr=1e-3,\n",
        "    stabilize=0\n",
        ")\n",
        "\n",
        "# Define loss function for link prediction: Binary Cross Entropy with logits\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "##############################################\n",
        "# Link Prediction Training Loop\n",
        "##############################################\n",
        "\n",
        "def get_positive_negative_samples(train_triples, num_nodes, num_neg_samples=5):\n",
        "    positive = set(train_triples)\n",
        "    negatives = []\n",
        "    while len(negatives) < len(train_triples) * num_neg_samples:\n",
        "        h = torch.randint(0, num_nodes, (1,)).item()\n",
        "        t = torch.randint(0, num_nodes, (1,)).item()\n",
        "        r = torch.randint(0, num_relations, (1,)).item()\n",
        "        if (h, r, t) not in positive:\n",
        "            negatives.append((h, r, t))\n",
        "    return train_triples, negatives\n",
        "\n",
        "train_pos, train_neg = get_positive_negative_samples(train_triples, num_nodes)\n",
        "\n",
        "# Convert to tensors\n",
        "train_pos = torch.tensor(train_pos, dtype=torch.long, device=device)\n",
        "train_neg = torch.tensor(train_neg, dtype=torch.long, device=device)\n",
        "\n",
        "def train_epoch(model, optimizer, criterion, pos_triples, neg_triples):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Combine positive and negative samples\n",
        "    pos_labels = torch.ones(pos_triples.size(0), device=device)\n",
        "    neg_labels = torch.zeros(neg_triples.size(0), device=device)\n",
        "    triples = torch.cat([pos_triples, neg_triples], dim=0)\n",
        "    labels = torch.cat([pos_labels, neg_labels], dim=0).unsqueeze(1)  # Shape: [2N, 1]\n",
        "\n",
        "    # Get embeddings\n",
        "    heads = triples[:,0]\n",
        "    relations = triples[:,1]\n",
        "    tails = triples[:,2]\n",
        "\n",
        "    head_emb = model.manifold.logmap0(model.manifold.expmap0(x, dim=-1)[heads], dim=-1)\n",
        "    tail_emb = model.manifold.logmap0(model.manifold.expmap0(x, dim=-1)[tails], dim=-1)\n",
        "\n",
        "    # For simplicity, ignore relations or handle them appropriately\n",
        "    # Here, we'll just use head and tail embeddings with a simple dot product\n",
        "    # A proper implementation should incorporate relation embeddings\n",
        "\n",
        "    # Compute score: inner product in tangent space\n",
        "    scores = (head_emb * tail_emb).sum(dim=-1, keepdim=True)  # Shape: [2N, 1]\n",
        "\n",
        "    loss = criterion(scores, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "# Enable anomaly detection to help debug further errors\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    loss = train_epoch(model, optimizer, criterion, train_pos, train_neg)\n",
        "    print(f\"Epoch {epoch}, Loss: {loss:.4f}, Curvature: {manifold.c.item():.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uXl5zklsFJE0",
        "outputId": "42b67ec8-3433-4dc1-8e91-cc9037da3780"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "can't optimize a non-leaf Tensor",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9a098c3cd331>\u001b[0m in \u001b[0;36m<cell line: 150>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;31m# Define optimizer using Geoopt's RiemannianAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m optimizer = geoopt.optim.RiemannianAdam(\n\u001b[0m\u001b[1;32m    151\u001b[0m     [\n\u001b[1;32m    152\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geoopt/optim/mixin.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stabilize, *args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stabilize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstabilize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/geoopt/optim/mixin.py\u001b[0m in \u001b[0;36madd_param_group\u001b[0;34m(self, param_group)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mparam_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stabilize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stabilize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstabilize_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36madd_param_group\u001b[0;34m(self, param_group)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretains_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m             ):\n\u001b[0;32m-> 1026\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"can't optimize a non-leaf Tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: can't optimize a non-leaf Tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "from torch import optim\n",
        "import geoopt\n",
        "from geoopt import ManifoldParameter\n",
        "\n",
        "##############################################\n",
        "# Data Loading (Example)\n",
        "##############################################\n",
        "\n",
        "def load_fb15k_data(train_path, valid_path, test_path):\n",
        "    def read_triples(path, ent2id, rel2id):\n",
        "        triples = []\n",
        "        with open(path, 'r') as f:\n",
        "            for line in f:\n",
        "                h, r, t = line.strip().split('\\t')\n",
        "                if h not in ent2id:\n",
        "                    ent2id[h] = len(ent2id)\n",
        "                if t not in ent2id:\n",
        "                    ent2id[t] = len(ent2id)\n",
        "                if r not in rel2id:\n",
        "                    rel2id[r] = len(rel2id)\n",
        "                triples.append((ent2id[h], rel2id[r], ent2id[t]))\n",
        "        return triples\n",
        "\n",
        "    ent2id = {}\n",
        "    rel2id = {}\n",
        "    train_triples = read_triples(train_path, ent2id, rel2id)\n",
        "    valid_triples = read_triples(valid_path, ent2id, rel2id)\n",
        "    test_triples = read_triples(test_path, ent2id, rel2id)\n",
        "\n",
        "    G = nx.Graph()\n",
        "    G.add_nodes_from(range(len(ent2id)))\n",
        "    for h, r, t in train_triples:\n",
        "        G.add_edge(h, t)\n",
        "\n",
        "    return ent2id, rel2id, G, train_triples, valid_triples, test_triples\n",
        "\n",
        "# Example paths (You must provide actual paths)\n",
        "train_path = 'train.txt'\n",
        "valid_path = 'valid.txt'\n",
        "test_path = 'test.txt'\n",
        "\n",
        "# For demonstration, create dummy data if files are not available\n",
        "import os\n",
        "if not os.path.exists(train_path):\n",
        "    with open(train_path, 'w') as f:\n",
        "        for i in range(100):\n",
        "            f.write(f\"entity_{i}\\trelation_{i%10}\\tentity_{(i+1)%100}\\n\")\n",
        "    with open(valid_path, 'w') as f:\n",
        "        for i in range(100, 120):\n",
        "            f.write(f\"entity_{i%100}\\trelation_{i%10}\\tentity_{(i+1)%100}\\n\")\n",
        "    with open(test_path, 'w') as f:\n",
        "        for i in range(120, 140):\n",
        "            f.write(f\"entity_{i%100}\\trelation_{i%10}\\tentity_{(i+1)%100}\\n\")\n",
        "\n",
        "ent2id, rel2id, G, train_triples, valid_triples, test_triples = load_fb15k_data(train_path, valid_path, test_path)\n",
        "\n",
        "num_nodes = len(ent2id)\n",
        "num_relations = len(rel2id)\n",
        "\n",
        "adj = nx.to_scipy_sparse_array(G, nodelist=range(num_nodes))\n",
        "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)  # symmetrize\n",
        "adj = torch.tensor(adj.toarray(), dtype=torch.float32) + 1e-5*torch.eye(num_nodes)\n",
        "degrees = adj.sum(axis=1)\n",
        "inv_sqrt_deg = 1. / torch.sqrt(degrees)\n",
        "inv_sqrt_deg[torch.isinf(inv_sqrt_deg)] = 0\n",
        "D_inv_sqrt = torch.diag(inv_sqrt_deg)\n",
        "norm_adj = D_inv_sqrt @ adj @ D_inv_sqrt\n",
        "norm_adj = norm_adj.to(torch.float32)\n",
        "\n",
        "# Node features: using identity for simplicity\n",
        "features = torch.eye(num_nodes, device='cpu')  # Initialize on CPU first\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "features, norm_adj = features.to(device), norm_adj.to(device)\n",
        "\n",
        "##############################################\n",
        "# Hyperbolic GCN Layers\n",
        "##############################################\n",
        "\n",
        "class HyperbolicLinear(nn.Module):\n",
        "    \"\"\"\n",
        "    Hyperbolic linear layer using the Poincaré Ball model.\n",
        "    \"\"\"\n",
        "    def __init__(self, manifold, in_features, out_features, bias=True):\n",
        "        super(HyperbolicLinear, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        # ManifoldParameter for weight in Euclidean space\n",
        "        self.weight = ManifoldParameter(torch.randn(out_features, in_features)*0.01, manifold=geoopt.Euclidean())\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is on manifold. Map to tangent space at 0, apply linear, map back\n",
        "        x_tan = self.manifold.logmap0(x, dim=-1)\n",
        "        out = F.linear(x_tan, self.weight, self.bias)\n",
        "        out = self.manifold.expmap0(out, dim=-1)\n",
        "        return out\n",
        "\n",
        "class HyperbolicGCNLayer(nn.Module):\n",
        "    def __init__(self, manifold, in_features, out_features):\n",
        "        super(HyperbolicGCNLayer, self).__init__()\n",
        "        self.manifold = manifold\n",
        "        self.lin = HyperbolicLinear(manifold, in_features, out_features)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # x on manifold\n",
        "        x_tan = self.manifold.logmap0(x, dim=-1)\n",
        "        x_agg_tan = adj @ x_tan  # aggregate in tangent space\n",
        "        x_agg = self.manifold.expmap0(x_agg_tan, dim=-1)\n",
        "        return self.lin(x_agg)\n",
        "\n",
        "class HyperbolicGCN(nn.Module):\n",
        "    def __init__(self, num_features, hidden_dim, num_classes, c=1.0):\n",
        "        super(HyperbolicGCN, self).__init__()\n",
        "        # Initialize the manifold inside the model to ensure its parameters are included\n",
        "        self.manifold = geoopt.PoincareBall(c=c, learnable=True)\n",
        "        self.layer1 = HyperbolicGCNLayer(self.manifold, num_features, hidden_dim)\n",
        "        self.layer2 = HyperbolicGCNLayer(self.manifold, hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.manifold.expmap0(x, dim=-1)  # ensure x is on manifold\n",
        "        x = self.layer1(x, adj)\n",
        "        # Hyperbolic activation: apply tanh in tangent space\n",
        "        x_tan = self.manifold.logmap0(x, dim=-1)\n",
        "        x_tan = torch.tanh(x_tan)\n",
        "        x = self.manifold.expmap0(x_tan, dim=-1)\n",
        "        x = self.layer2(x, adj)\n",
        "        return x\n",
        "\n",
        "##############################################\n",
        "# Link Prediction Utilities\n",
        "##############################################\n",
        "\n",
        "def get_positive_negative_samples(train_triples, num_nodes, num_neg_samples=5):\n",
        "    positive = set(train_triples)\n",
        "    negatives = []\n",
        "    while len(negatives) < len(train_triples) * num_neg_samples:\n",
        "        h = torch.randint(0, num_nodes, (1,)).item()\n",
        "        t = torch.randint(0, num_nodes, (1,)).item()\n",
        "        r = torch.randint(0, num_relations, (1,)).item()\n",
        "        if (h, r, t) not in positive:\n",
        "            negatives.append((h, r, t))\n",
        "    return train_triples, negatives\n",
        "\n",
        "def train_epoch(model, optimizer, criterion, pos_triples, neg_triples):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Combine positive and negative samples\n",
        "    pos_labels = torch.ones(pos_triples.size(0), device=device)\n",
        "    neg_labels = torch.zeros(neg_triples.size(0), device=device)\n",
        "    triples = torch.cat([pos_triples, neg_triples], dim=0)\n",
        "    labels = torch.cat([pos_labels, neg_labels], dim=0).unsqueeze(1)  # Shape: [2N, 1]\n",
        "\n",
        "    # Get embeddings\n",
        "    heads = triples[:,0]\n",
        "    relations = triples[:,1]\n",
        "    tails = triples[:,2]\n",
        "\n",
        "    # Forward pass through the model\n",
        "    logits = model(features, norm_adj)  # Shape: [num_nodes, num_relations]\n",
        "\n",
        "    # For link prediction, define a scoring function\n",
        "    # Here, we'll use a simple dot product between head and tail embeddings\n",
        "    # A proper implementation should incorporate relation embeddings\n",
        "    # For demonstration, we'll compute scores for each triple\n",
        "    head_emb = logits[heads]  # Shape: [2N, num_classes]\n",
        "    tail_emb = logits[tails]  # Shape: [2N, num_classes]\n",
        "\n",
        "    # Simple dot product scoring\n",
        "    scores = (head_emb * tail_emb).sum(dim=1, keepdim=True)  # Shape: [2N, 1]\n",
        "\n",
        "    loss = criterion(scores, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "##############################################\n",
        "# Model and Training\n",
        "##############################################\n",
        "\n",
        "model = HyperbolicGCN(num_features=num_nodes, hidden_dim=64, num_classes=num_relations, c=0.0001).to(device)\n",
        "\n",
        "# Initialize input: ensure features are on the manifold\n",
        "# Here, features are identity; map them to the manifold\n",
        "x = model.manifold.expmap0(features, dim=-1)\n",
        "\n",
        "# Define optimizer using Geoopt's RiemannianAdam\n",
        "optimizer = geoopt.optim.RiemannianAdam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Define loss function for link prediction: Binary Cross Entropy with logits\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Prepare training samples\n",
        "train_pos, train_neg = get_positive_negative_samples(train_triples, num_nodes)\n",
        "\n",
        "# Convert to tensors\n",
        "train_pos = torch.tensor(train_pos, dtype=torch.long, device=device)\n",
        "train_neg = torch.tensor(train_neg, dtype=torch.long, device=device)\n",
        "\n",
        "# Enable anomaly detection to help debug further errors\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    loss = train_epoch(model, optimizer, criterion, train_pos, train_neg)\n",
        "    print(f\"Epoch {epoch}, Loss: {loss:.4f}, Curvature: {model.manifold.c.item():.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je2snX0DJWcL",
        "outputId": "2093165c-10a0-4282-cc08-edccce57e42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6931, Curvature: 0.000100\n",
            "Epoch 1, Loss: 0.6932, Curvature: 0.000100\n",
            "Epoch 2, Loss: 0.6932, Curvature: 0.000100\n",
            "Epoch 3, Loss: 0.6932, Curvature: 0.000100\n",
            "Epoch 4, Loss: 0.6932, Curvature: 0.000100\n",
            "Epoch 5, Loss: 0.6932, Curvature: 0.000100\n",
            "Epoch 6, Loss: 0.6932, Curvature: 0.000100\n",
            "Epoch 7, Loss: 0.6931, Curvature: 0.000100\n",
            "Epoch 8, Loss: 0.6932, Curvature: 0.000100\n",
            "Epoch 9, Loss: 0.6932, Curvature: 0.000100\n",
            "Epoch 10, Loss: 0.6932, Curvature: 0.000100\n",
            "Epoch 11, Loss: 0.6931, Curvature: 0.000100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geoopt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVxzXfjpKL9o",
        "outputId": "8a32274d-97ab-4869-ade2-ddae207b572a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geoopt\n",
            "  Downloading geoopt-0.5.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from geoopt) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from geoopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from geoopt) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->geoopt) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->geoopt) (3.0.2)\n",
            "Downloading geoopt-0.5.0-py3-none-any.whl (90 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/90.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: geoopt\n",
            "Successfully installed geoopt-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Dr3YGekwDNE8"
      }
    }
  ]
}